{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.insert(0,'../..')\n",
    "\n",
    "from methods.bag_of_ngrams.processing import (cleanReport, cleanReports, cleanSplit, getCounter, \n",
    "                                              getTrainedVectorizer, STRIPCHARS, unkReports)\n",
    "from methods.sklearn_calibration import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pyfunctions.general import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'domain': 'prostate',\n",
    "        'epochs': 20,\n",
    "        'embeddingDim': 300,\n",
    "        'maxDocLength': 1346,\n",
    "        'target_fields': ['TreatmentEffect','TumorType','PrimaryGleason','SecondaryGleason','TertiaryGleason',\n",
    "                          'SeminalVesicleNone','LymphNodesNone','MarginStatusNone','ExtraprostaticExtension',\n",
    "                          'PerineuralInfiltration','RbCribriform','BenignMargins'],\n",
    "        'n_tries': 20 # Number of random search candidates\n",
    "        }\n",
    "\n",
    "# Read in data\n",
    "path = \"../../data/\" + args['domain'] + \".json\"\n",
    "data = readJson(path)\n",
    "\n",
    "# Process reports\n",
    "data = cleanSplit(data, STRIPCHARS)\n",
    "\n",
    "# Unk rare words\n",
    "counter = getCounter(data['train'])\n",
    "data['train'] = unkReports(data['train'], counter)\n",
    "data['val'] = unkReports(data['val'], counter)\n",
    "data['test'] = unkReports(data['test'], counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Vectorize text and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                penalty='l1',\n",
       "                                                solver='liblinear'),\n",
       "                   n_iter=20, n_jobs=20,\n",
       "                   param_distributions={'C': array([1.00000000e-06, 1.02804473e-06, 1.05687597e-06, 1.08651577e-06,\n",
       "       1.11698682e-06, 1.14831241e-06, 1.18051653e-06, 1.21362380e-06,\n",
       "       1.24765955e-06, 1.28264983e-06, 1.31862140e-06, 1.35560179e-06,\n",
       "       1.393619...\n",
       "       5.29326606e+05, 5.44171429e+05, 5.59432571e+05, 5.75121707e+05,\n",
       "       5.91250841e+05, 6.07832313e+05, 6.24878807e+05, 6.42403366e+05,\n",
       "       6.60419396e+05, 6.78940681e+05, 6.97981391e+05, 7.17556092e+05,\n",
       "       7.37679760e+05, 7.58367791e+05, 7.79636013e+05, 8.01500696e+05,\n",
       "       8.23978568e+05, 8.47086827e+05, 8.70843150e+05, 8.95265713e+05,\n",
       "       9.20373200e+05, 9.46184819e+05, 9.72720319e+05, 1.00000000e+06])})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random search parameters\n",
    "params = { 'C': np.logspace(-6,6,1000)}\n",
    "\n",
    "field = args['target_fields'][3]\n",
    "N = 3\n",
    "    \n",
    "# Extract labels and reports\n",
    "corpus_train = extractListFromDic(data['train'], 'clean_document_unked')\n",
    "y_train = extractListFromDic(data['train'], 'labels', field)\n",
    "\n",
    "corpus_val = extractListFromDic(data['val'], 'clean_document_unked')\n",
    "y_val = extractListFromDic(data['val'], 'labels', field)\n",
    "\n",
    "corpus_test = extractListFromDic(data['test'], 'clean_document_unked')\n",
    "y_test = extractListFromDic(data['test'], 'labels', field)\n",
    "\n",
    "# Vectorizer documents\n",
    "vectorizer = getTrainedVectorizer(corpus_train, N, 1)  \n",
    "X_train = vectorizer.transform(corpus_train)\n",
    "X_val = vectorizer.transform(corpus_val)\n",
    "X_test = vectorizer.transform(corpus_test)\n",
    "\n",
    "model = LogisticRegression(penalty = 'l1', class_weight = 'balanced',solver = 'liblinear')\n",
    "clf = RandomizedSearchCV(model, params, cv=3, n_iter = 20, n_jobs = 20)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_val = pd.DataFrame({'label': np.array(y_val).astype(str), \n",
    "                         'prediction': clf.predict(X_val), \n",
    "                         'probability': np.max(clf.predict_proba(X_val), axis=1)})\n",
    "\n",
    "pred_test = pd.DataFrame({'label': np.array(y_test).astype(str), \n",
    "                          'prediction': clf.predict(X_test), \n",
    "                          'probability': np.max(clf.predict_proba(X_test), axis=1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calibrate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 0.1), (0.1, 0.2), (0.2, 0.30000000000000004), (0.30000000000000004, 0.4), (0.4, 0.5), (0.5, 0.6000000000000001), (0.6000000000000001, 0.7000000000000001), (0.7000000000000001, 0.8), (0.8, 0.9), (0.9, 1.0)]\n",
      "{0.9923587371807763, 0.9832002203249794, 0.9920593689471917, 0.9918534696447951, 0.989118076985545, 0.4691943127962085, 0.9782450046060024, 0.9805750552937783, 0.7154574132492113, 0.9828666457169396, 0.9914529914529915, 0.45013715467749915, 0.7776581554024685, 1.0, 0.886001074487398, 0.5238095238095238, 0.9759462604285754, 0.5743740795287187, 0.8571607987608323, 0.5215200380407307, 0.5982905982905984, 0.9710346814338391, 0.9839412997182895, 0.8518822275075864, 0.6976744186046512, 0.7906295754026355, 0.678652108433735, 0.9790874524714829, 0.9889006801962351, 0.8865435356200528, 0.8824836048233552, 0.9955587132043486, 0.9934250579751882, 0.9964302533761475, 0.9823637512134542, 0.5988593155893536, 0.9940378300290317, 0.9975768335692522, 0.43893711339692926, 0.8698187877525515, 0.9741439108071139, 0.9861436131802828, 0.9949041476279766, 0.9950910583311795, 0.9855072463768116, 0.5913293387144957, 0.9815512358747355, 0.8237843195523623, 0.8513569383516283, 0.997624703087886, 0.9786666063389363, 0.5366936899044775, 0.9947089947089948, 0.5225062203121466, 0.9919092677121591, 0.8638545470899762, 0.9735104997762796, 0.9610030185369509, 0.9804089977061703, 0.9730422023910079, 0.5988907931754142, 0.888888888888889, 0.8754239724058637, 0.7924528301886793, 0.4487179487179487, 0.7638016543534538, 0.8735435468904986, 0.9398570804829196, 0.8480376292687025, 0.9765832229052335}\n"
     ]
    }
   ],
   "source": [
    "classes = clf.classes_\n",
    "\n",
    "calibrated_scores = np.zeros((pred_test.shape[0], len(classes)))\n",
    "\n",
    "pred_test['correct'] = pred_test['label'] == pred_test['prediction']\n",
    "pred_val['correct'] = pred_val['label'] == pred_val['prediction']\n",
    "\n",
    "probs_val = clf.predict_proba(X_val)\n",
    "probs_test = clf.predict_proba(X_test)\n",
    "\n",
    "# Multiclass calibration\n",
    "for p in range(len(classes)):\n",
    "    pred_val['correct'] = pred_val['label'] == classes[p]\n",
    "    pred_val['correct'] = pred_val['correct'].astype(int)\n",
    "\n",
    "    X = probs_val[:,p].reshape(-1,)\n",
    "    y = pred_val['correct']\n",
    "\n",
    "    reg = IsotonicRegression()\n",
    "    reg.fit(X,y)\n",
    "\n",
    "    X_eval = probs_test[:,p].reshape(-1,)\n",
    "    X_eval[X_eval < reg.X_min_] = reg.X_min_\n",
    "    X_eval[X_eval > reg.X_max_] = reg.X_max_\n",
    "\n",
    "    calibrated_scores[:,p] = reg.predict(X_eval)\n",
    "\n",
    "# Normalize calibrated scores\n",
    "row_sums = calibrated_scores.sum(axis=1)\n",
    "calibrated_scores = calibrated_scores / row_sums[:, np.newaxis]\n",
    "calibrated_scores = np.max(calibrated_scores, axis = 1)\n",
    "\n",
    "# Calculate expected calibration error\n",
    "ece = ece_mce_error(calibrated_scores, pred_test['prediction'].astype(str), \n",
    "                            pred_test['label'].astype(str), num_bins = 10, plot = None)\n",
    "\n",
    "pred_test['calibrated_score'] = calibrated_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected calibration error: 0.015619947722185178\n"
     ]
    }
   ],
   "source": [
    "print('expected calibration error:', ece[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
