{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "basedir = \"/media/pathologyhd/path_nlp/pathparsing/\"\n",
    "sys.path.append(basedir + \"prostate-open-source/\")\n",
    "\n",
    "from methods.bag_of_ngrams.processing import (cleanReport, cleanReports, cleanSplit, getCounter, \n",
    "                                              getTrainedVectorizer, STRIPCHARS, unkReports)\n",
    "from methods.sklearn_calibration import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pyfunctions.general import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'domain': 'prostate',\n",
    "        'epochs': 20,\n",
    "        'embeddingDim': 300,\n",
    "        'maxDocLength': 1346,\n",
    "        'path': basedir + \"prostate-open-source/\",\n",
    "        'target_fields': ['TreatmentEffect','TumorType','PrimaryGleason','SecondaryGleason','TertiaryGleason',\n",
    "                          'SeminalVesicleNone','LymphNodesNone','MarginStatusNone','ExtraprostaticExtension',\n",
    "                          'PerineuralInfiltration','RbCribriform','BenignMargins'],\n",
    "        'n_tries': 20 # Number of random search candidates\n",
    "        }\n",
    "\n",
    "# Read in data\n",
    "path = args['path'] + \"data/splits/\" + args['domain'] + \".json\"\n",
    "data = readJson(path)\n",
    "\n",
    "# Process reports\n",
    "data = cleanSplit(data, STRIPCHARS)\n",
    "\n",
    "# Unk rare words\n",
    "counter = getCounter(data['train'])\n",
    "data['train'] = unkReports(data['train'], counter)\n",
    "data['val'] = unkReports(data['val'], counter)\n",
    "data['test'] = unkReports(data['test'], counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Vectorize text and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=20, n_jobs=20,\n",
       "          param_distributions={'C': array([1.00000e-06, 1.02804e-06, ..., 9.72720e+05, 1.00000e+06])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random search parameters\n",
    "params = { 'C': np.logspace(-6,6,1000)}\n",
    "\n",
    "field = args['target_fields'][3]\n",
    "N = 3\n",
    "    \n",
    "# Extract labels and reports\n",
    "corpus_train = extractListFromDic(data['train'], 'clean_document_unked')\n",
    "y_train = extractListFromDic(data['train'], 'labels', field)\n",
    "\n",
    "corpus_val = extractListFromDic(data['val'], 'clean_document_unked')\n",
    "y_val = extractListFromDic(data['val'], 'labels', field)\n",
    "\n",
    "corpus_test = extractListFromDic(data['test'], 'clean_document_unked')\n",
    "y_test = extractListFromDic(data['test'], 'labels', field)\n",
    "\n",
    "# Vectorizer documents\n",
    "vectorizer = getTrainedVectorizer(corpus_train, N, 1)  \n",
    "X_train = vectorizer.transform(corpus_train)\n",
    "X_val = vectorizer.transform(corpus_val)\n",
    "X_test = vectorizer.transform(corpus_test)\n",
    "\n",
    "model = LogisticRegression(penalty = 'l1', class_weight = 'balanced',solver = 'liblinear')\n",
    "clf = RandomizedSearchCV(model, params, cv=3, n_iter = 20, n_jobs = 20)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_val = pd.DataFrame({'label': np.array(y_val).astype(str), \n",
    "                         'prediction': clf.predict(X_val), \n",
    "                         'probability': np.max(clf.predict_proba(X_val), axis=1)})\n",
    "\n",
    "pred_test = pd.DataFrame({'label': np.array(y_test).astype(str), \n",
    "                          'prediction': clf.predict(X_test), \n",
    "                          'probability': np.max(clf.predict_proba(X_test), axis=1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label prediction  probability\n",
       "0     3          3     0.996676\n",
       "1     3          3     0.999946\n",
       "2     4          4     0.999949\n",
       "3     4          4     0.999988\n",
       "4     4          4     0.999999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calibrate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 0.1), (0.1, 0.2), (0.2, 0.30000000000000004), (0.30000000000000004, 0.4), (0.4, 0.5), (0.5, 0.6000000000000001), (0.6000000000000001, 0.7000000000000001), (0.7000000000000001, 0.8), (0.8, 0.9), (0.9, 1.0)]\n",
      "{0.9904697427351317, 0.9874887650548265, 0.5685660613650595, 0.983117737338303, 0.9788227600996259, 0.9918032786885246, 0.9778085991678225, 0.9455460580552784, 0.8, 0.9861432590733963, 0.826164290363952, 0.9916963226571768, 0.9769163721281765, 1.0, 0.9629651388676911, 0.9675851227558498, 0.9764744001344694, 0.5714285714285714, 0.8864192416081454, 0.9360904253705534, 0.6960048088433503, 0.997498159131251, 0.5454545454545454, 0.9725961893963668, 0.5968448729184925, 0.9955565814530556, 0.9387483355525964, 0.8705303674531102, 0.8727652355474357, 0.6277561608300909, 0.9782446919185197, 0.627906976744186, 0.9873262299175892, 0.9559960448425063, 0.9491525423728814, 0.7580880818200794, 0.947017180016858, 0.9824786324786324, 0.9789571445566319, 0.9402910740966188, 0.6724256235460819, 0.9833333333333334, 0.9700037807157161, 0.9510064660089191, 0.9622663662942009, 0.8336223605018872, 0.7553130883149645, 0.9438409825689799, 0.9504950495049506, 0.8773149273574187, 0.987225968968832, 0.97416653499763, 0.4959016393442623, 0.9624504126430047, 0.9735258870835284, 0.9681886557640378, 0.9440772372818418, 0.8727272727272727, 0.7395932772821162, 0.6180045997152558, 0.9850865581769576, 0.9667057825897025, 0.9790920388917319, 0.9598395661970985, 0.9439420386467496}\n"
     ]
    }
   ],
   "source": [
    "classes = clf.classes_\n",
    "\n",
    "calibrated_scores = np.zeros((pred_test.shape[0], len(classes)))\n",
    "\n",
    "pred_test['correct'] = pred_test['label'] == pred_test['prediction']\n",
    "pred_val['correct'] = pred_val['label'] == pred_val['prediction']\n",
    "\n",
    "probs_val = clf.predict_proba(X_val)\n",
    "probs_test = clf.predict_proba(X_test)\n",
    "\n",
    "# Multiclass calibration\n",
    "for p in range(len(classes)):\n",
    "    pred_val['correct'] = pred_val['label'] == classes[p]\n",
    "    pred_val['correct'] = pred_val['correct'].astype(int)\n",
    "\n",
    "    X = probs_val[:,p].reshape(-1,)\n",
    "    y = pred_val['correct']\n",
    "\n",
    "    reg = IsotonicRegression()\n",
    "    reg.fit(X,y)\n",
    "\n",
    "    X_eval = probs_test[:,p].reshape(-1,)\n",
    "    X_eval[X_eval < reg.X_min_] = reg.X_min_\n",
    "    X_eval[X_eval > reg.X_max_] = reg.X_max_\n",
    "\n",
    "    calibrated_scores[:,p] = reg.predict(X_eval)\n",
    "\n",
    "# Normalize calibrated scores\n",
    "row_sums = calibrated_scores.sum(axis=1)\n",
    "calibrated_scores = calibrated_scores / row_sums[:, np.newaxis]\n",
    "calibrated_scores = np.max(calibrated_scores, axis = 1)\n",
    "\n",
    "# Calculate expected calibration error\n",
    "ece = ece_mce_error(calibrated_scores, pred_test['prediction'].astype(str), \n",
    "                            pred_test['label'].astype(str), num_bins = 10, plot = None)\n",
    "\n",
    "pred_test['calibrated_score'] = calibrated_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected calibration error: 0.018677780379608787\n"
     ]
    }
   ],
   "source": [
    "print('expected calibration error:', ece[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
